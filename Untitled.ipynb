{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    # path to training data\n",
    "    training_data_path = 'data/conversations_lenmax22_formersents2_with_former'\n",
    "\n",
    "    # path to all_words\n",
    "    all_words_path = 'data/all_words.txt'\n",
    "\n",
    "    # training parameters \n",
    "    CHECKPOINT = True\n",
    "    train_model_path = 'model'\n",
    "    train_model_name = 'model-55'\n",
    "    start_epoch = 56\n",
    "    start_batch = 0\n",
    "    batch_size = 25\n",
    "\n",
    "    # for RL training\n",
    "    training_type = 'normal' # 'normal' for seq2seq training, 'pg' for policy gradient\n",
    "    reversed_model_path = 'Adam_encode22_decode22_reversed-maxlen22_lr0.0001_batch25_wordthres6'\n",
    "    reversed_model_name = 'model-63'\n",
    "\n",
    "    # data reader shuffle index list\n",
    "    load_list = False\n",
    "    index_list_file = 'data/shuffle_index_list'\n",
    "    cur_train_index = start_batch * batch_size\n",
    "\n",
    "    # word count threshold\n",
    "    WC_threshold = 20\n",
    "    reversed_WC_threshold = 6\n",
    "\n",
    "    # dialog simulation turns\n",
    "    MAX_TURNS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VSCADMIN\\Anaconda2_64\\envs\\HIRA\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Elapsed: 11.113264799118042 secs\n",
      "\n",
      "len conversation 83097\n",
      "con_count 1000, traindata_count 2049\n",
      "con_count 2000, traindata_count 3996\n",
      "con_count 3000, traindata_count 6425\n",
      "con_count 4000, traindata_count 8353\n",
      "con_count 5000, traindata_count 10654\n",
      "con_count 6000, traindata_count 12707\n",
      "con_count 7000, traindata_count 14666\n",
      "con_count 8000, traindata_count 16673\n",
      "con_count 9000, traindata_count 18578\n",
      "con_count 10000, traindata_count 20317\n",
      "con_count 11000, traindata_count 22826\n",
      "con_count 12000, traindata_count 25611\n",
      "con_count 13000, traindata_count 27879\n",
      "con_count 14000, traindata_count 30057\n",
      "con_count 15000, traindata_count 32631\n",
      "con_count 16000, traindata_count 34686\n",
      "con_count 17000, traindata_count 36849\n",
      "con_count 18000, traindata_count 38890\n",
      "con_count 19000, traindata_count 41103\n",
      "con_count 20000, traindata_count 43175\n",
      "con_count 21000, traindata_count 45123\n",
      "con_count 22000, traindata_count 47305\n",
      "con_count 23000, traindata_count 48998\n",
      "con_count 24000, traindata_count 51571\n",
      "con_count 25000, traindata_count 53672\n",
      "con_count 26000, traindata_count 55744\n",
      "con_count 27000, traindata_count 57609\n",
      "con_count 28000, traindata_count 59333\n",
      "con_count 29000, traindata_count 61598\n",
      "con_count 30000, traindata_count 63880\n",
      "con_count 31000, traindata_count 65773\n",
      "con_count 32000, traindata_count 67893\n",
      "con_count 33000, traindata_count 70072\n",
      "con_count 34000, traindata_count 72632\n",
      "con_count 35000, traindata_count 75087\n",
      "con_count 36000, traindata_count 77276\n",
      "con_count 37000, traindata_count 79020\n",
      "con_count 38000, traindata_count 81055\n",
      "con_count 39000, traindata_count 83212\n",
      "con_count 40000, traindata_count 85462\n",
      "con_count 41000, traindata_count 87717\n",
      "con_count 42000, traindata_count 90933\n",
      "con_count 43000, traindata_count 93730\n",
      "con_count 44000, traindata_count 95726\n",
      "con_count 45000, traindata_count 97907\n",
      "con_count 46000, traindata_count 100056\n",
      "con_count 47000, traindata_count 102594\n",
      "con_count 48000, traindata_count 104500\n",
      "con_count 49000, traindata_count 106753\n",
      "con_count 50000, traindata_count 108974\n",
      "con_count 51000, traindata_count 111087\n",
      "con_count 52000, traindata_count 113508\n",
      "con_count 53000, traindata_count 115709\n",
      "con_count 54000, traindata_count 117896\n",
      "con_count 55000, traindata_count 119670\n",
      "con_count 56000, traindata_count 121593\n",
      "con_count 57000, traindata_count 123375\n",
      "con_count 58000, traindata_count 125332\n",
      "con_count 59000, traindata_count 127916\n",
      "con_count 60000, traindata_count 130063\n",
      "con_count 61000, traindata_count 132035\n",
      "con_count 62000, traindata_count 134442\n",
      "con_count 63000, traindata_count 136628\n",
      "con_count 64000, traindata_count 138860\n",
      "con_count 65000, traindata_count 140717\n",
      "con_count 66000, traindata_count 143000\n",
      "con_count 67000, traindata_count 145005\n",
      "con_count 68000, traindata_count 147070\n",
      "con_count 69000, traindata_count 149109\n",
      "con_count 70000, traindata_count 151472\n",
      "con_count 71000, traindata_count 153787\n",
      "con_count 72000, traindata_count 155705\n",
      "con_count 73000, traindata_count 157753\n",
      "con_count 74000, traindata_count 160029\n",
      "con_count 75000, traindata_count 162029\n",
      "con_count 76000, traindata_count 164162\n",
      "con_count 77000, traindata_count 166159\n",
      "con_count 78000, traindata_count 168425\n",
      "con_count 79000, traindata_count 170328\n",
      "con_count 80000, traindata_count 172567\n",
      "con_count 81000, traindata_count 174927\n",
      "con_count 82000, traindata_count 176857\n",
      "con_count 83000, traindata_count 178575\n",
      "Time Elapsed: 3.8018972873687744 secs\n",
      "\n",
      "max_a_ind 10, max_b_ind 0\n",
      "max_a 22, max_b 22, avg_a 7.424128170416531, avg_b 7.383465165974871\n",
      "len conversation 83097\n",
      "con_count 1000, traindata_count 1942\n",
      "con_count 2000, traindata_count 3782\n",
      "con_count 3000, traindata_count 6095\n",
      "con_count 4000, traindata_count 7888\n",
      "con_count 5000, traindata_count 10079\n",
      "con_count 6000, traindata_count 12042\n",
      "con_count 7000, traindata_count 13890\n",
      "con_count 8000, traindata_count 15781\n",
      "con_count 9000, traindata_count 17571\n",
      "con_count 10000, traindata_count 19183\n",
      "con_count 11000, traindata_count 21543\n",
      "con_count 12000, traindata_count 24160\n",
      "con_count 13000, traindata_count 26267\n",
      "con_count 14000, traindata_count 28381\n",
      "con_count 15000, traindata_count 30743\n",
      "con_count 16000, traindata_count 32700\n",
      "con_count 17000, traindata_count 34766\n",
      "con_count 18000, traindata_count 36692\n",
      "con_count 19000, traindata_count 38768\n",
      "con_count 20000, traindata_count 40717\n",
      "con_count 21000, traindata_count 42566\n",
      "con_count 22000, traindata_count 44584\n",
      "con_count 23000, traindata_count 46159\n",
      "con_count 24000, traindata_count 48564\n",
      "con_count 25000, traindata_count 50524\n",
      "con_count 26000, traindata_count 52474\n",
      "con_count 27000, traindata_count 54240\n",
      "con_count 28000, traindata_count 55877\n",
      "con_count 29000, traindata_count 57972\n",
      "con_count 30000, traindata_count 60124\n",
      "con_count 31000, traindata_count 61895\n",
      "con_count 32000, traindata_count 63927\n",
      "con_count 33000, traindata_count 66007\n",
      "con_count 34000, traindata_count 68427\n",
      "con_count 35000, traindata_count 70730\n",
      "con_count 36000, traindata_count 72786\n",
      "con_count 37000, traindata_count 74451\n",
      "con_count 38000, traindata_count 76352\n",
      "con_count 39000, traindata_count 78404\n",
      "con_count 40000, traindata_count 80502\n",
      "con_count 41000, traindata_count 82607\n",
      "con_count 42000, traindata_count 85710\n",
      "con_count 43000, traindata_count 88318\n",
      "con_count 44000, traindata_count 90168\n",
      "con_count 45000, traindata_count 92245\n",
      "con_count 46000, traindata_count 94259\n",
      "con_count 47000, traindata_count 96661\n",
      "con_count 48000, traindata_count 98455\n",
      "con_count 49000, traindata_count 100616\n",
      "con_count 50000, traindata_count 102737\n",
      "con_count 51000, traindata_count 104773\n",
      "con_count 52000, traindata_count 107028\n",
      "con_count 53000, traindata_count 109106\n",
      "con_count 54000, traindata_count 111156\n",
      "con_count 55000, traindata_count 112837\n",
      "con_count 56000, traindata_count 114695\n",
      "con_count 57000, traindata_count 116409\n",
      "con_count 58000, traindata_count 118216\n",
      "con_count 59000, traindata_count 120675\n",
      "con_count 60000, traindata_count 122696\n",
      "con_count 61000, traindata_count 124541\n",
      "con_count 62000, traindata_count 126814\n",
      "con_count 63000, traindata_count 128903\n",
      "con_count 64000, traindata_count 131005\n",
      "con_count 65000, traindata_count 132740\n",
      "con_count 66000, traindata_count 134845\n",
      "con_count 67000, traindata_count 136684\n",
      "con_count 68000, traindata_count 138620\n",
      "con_count 69000, traindata_count 140538\n",
      "con_count 70000, traindata_count 142818\n",
      "con_count 71000, traindata_count 144937\n",
      "con_count 72000, traindata_count 146752\n",
      "con_count 73000, traindata_count 148717\n",
      "con_count 74000, traindata_count 150846\n",
      "con_count 75000, traindata_count 152730\n",
      "con_count 76000, traindata_count 154747\n",
      "con_count 77000, traindata_count 156613\n",
      "con_count 78000, traindata_count 158773\n",
      "con_count 79000, traindata_count 160557\n",
      "con_count 80000, traindata_count 162630\n",
      "con_count 81000, traindata_count 164841\n",
      "con_count 82000, traindata_count 166668\n",
      "con_count 83000, traindata_count 168293\n",
      "Time Elapsed: 4.4806811809539795 secs\n",
      "\n",
      "len conversation 83097\n",
      "con_count 1000, traindata_count 1942\n",
      "con_count 2000, traindata_count 3782\n",
      "con_count 3000, traindata_count 6095\n",
      "con_count 4000, traindata_count 7888\n",
      "con_count 5000, traindata_count 10079\n",
      "con_count 6000, traindata_count 12042\n",
      "con_count 7000, traindata_count 13890\n",
      "con_count 8000, traindata_count 15781\n",
      "con_count 9000, traindata_count 17571\n",
      "con_count 10000, traindata_count 19183\n",
      "con_count 11000, traindata_count 21543\n",
      "con_count 12000, traindata_count 24160\n",
      "con_count 13000, traindata_count 26267\n",
      "con_count 14000, traindata_count 28381\n",
      "con_count 15000, traindata_count 30743\n",
      "con_count 16000, traindata_count 32700\n",
      "con_count 17000, traindata_count 34766\n",
      "con_count 18000, traindata_count 36692\n",
      "con_count 19000, traindata_count 38768\n",
      "con_count 20000, traindata_count 40717\n",
      "con_count 21000, traindata_count 42566\n",
      "con_count 22000, traindata_count 44584\n",
      "con_count 23000, traindata_count 46159\n",
      "con_count 24000, traindata_count 48564\n",
      "con_count 25000, traindata_count 50524\n",
      "con_count 26000, traindata_count 52474\n",
      "con_count 27000, traindata_count 54240\n",
      "con_count 28000, traindata_count 55877\n",
      "con_count 29000, traindata_count 57972\n",
      "con_count 30000, traindata_count 60124\n",
      "con_count 31000, traindata_count 61895\n",
      "con_count 32000, traindata_count 63927\n",
      "con_count 33000, traindata_count 66007\n",
      "con_count 34000, traindata_count 68427\n",
      "con_count 35000, traindata_count 70730\n",
      "con_count 36000, traindata_count 72786\n",
      "con_count 37000, traindata_count 74451\n",
      "con_count 38000, traindata_count 76352\n",
      "con_count 39000, traindata_count 78404\n",
      "con_count 40000, traindata_count 80502\n",
      "con_count 41000, traindata_count 82607\n",
      "con_count 42000, traindata_count 85710\n",
      "con_count 43000, traindata_count 88318\n",
      "con_count 44000, traindata_count 90168\n",
      "con_count 45000, traindata_count 92245\n",
      "con_count 46000, traindata_count 94259\n",
      "con_count 47000, traindata_count 96661\n",
      "con_count 48000, traindata_count 98455\n",
      "con_count 49000, traindata_count 100616\n",
      "con_count 50000, traindata_count 102737\n",
      "con_count 51000, traindata_count 104773\n",
      "con_count 52000, traindata_count 107028\n",
      "con_count 53000, traindata_count 109106\n",
      "con_count 54000, traindata_count 111156\n",
      "con_count 55000, traindata_count 112837\n",
      "con_count 56000, traindata_count 114695\n",
      "con_count 57000, traindata_count 116409\n",
      "con_count 58000, traindata_count 118216\n",
      "con_count 59000, traindata_count 120675\n",
      "con_count 60000, traindata_count 122696\n",
      "con_count 61000, traindata_count 124541\n",
      "con_count 62000, traindata_count 126814\n",
      "con_count 63000, traindata_count 128903\n",
      "con_count 64000, traindata_count 131005\n",
      "con_count 65000, traindata_count 132740\n",
      "con_count 66000, traindata_count 134845\n",
      "con_count 67000, traindata_count 136684\n",
      "con_count 68000, traindata_count 138620\n",
      "con_count 69000, traindata_count 140538\n",
      "con_count 70000, traindata_count 142818\n",
      "con_count 71000, traindata_count 144937\n",
      "con_count 72000, traindata_count 146752\n",
      "con_count 73000, traindata_count 148717\n",
      "con_count 74000, traindata_count 150846\n",
      "con_count 75000, traindata_count 152730\n",
      "con_count 76000, traindata_count 154747\n",
      "con_count 77000, traindata_count 156613\n",
      "con_count 78000, traindata_count 158773\n",
      "con_count 79000, traindata_count 160557\n",
      "con_count 80000, traindata_count 162630\n",
      "con_count 81000, traindata_count 164841\n",
      "con_count 82000, traindata_count 166668\n",
      "con_count 83000, traindata_count 168293\n",
      "Time Elapsed: 4.42831563949585 secs\n",
      "\n",
      "len conversation 83097\n",
      "con_count 1000, traindata_count 2049\n",
      "con_count 2000, traindata_count 3996\n",
      "con_count 3000, traindata_count 6425\n",
      "con_count 4000, traindata_count 8353\n",
      "con_count 5000, traindata_count 10654\n",
      "con_count 6000, traindata_count 12707\n",
      "con_count 7000, traindata_count 14666\n",
      "con_count 8000, traindata_count 16673\n",
      "con_count 9000, traindata_count 18578\n",
      "con_count 10000, traindata_count 20317\n",
      "con_count 11000, traindata_count 22826\n",
      "con_count 12000, traindata_count 25611\n",
      "con_count 13000, traindata_count 27879\n",
      "con_count 14000, traindata_count 30057\n",
      "con_count 15000, traindata_count 32631\n",
      "con_count 16000, traindata_count 34686\n",
      "con_count 17000, traindata_count 36849\n",
      "con_count 18000, traindata_count 38890\n",
      "con_count 19000, traindata_count 41103\n",
      "con_count 20000, traindata_count 43175\n",
      "con_count 21000, traindata_count 45123\n",
      "con_count 22000, traindata_count 47305\n",
      "con_count 23000, traindata_count 48998\n",
      "con_count 24000, traindata_count 51571\n",
      "con_count 25000, traindata_count 53672\n",
      "con_count 26000, traindata_count 55744\n",
      "con_count 27000, traindata_count 57609\n",
      "con_count 28000, traindata_count 59333\n",
      "con_count 29000, traindata_count 61598\n",
      "con_count 30000, traindata_count 63880\n",
      "con_count 31000, traindata_count 65773\n",
      "con_count 32000, traindata_count 67893\n",
      "con_count 33000, traindata_count 70072\n",
      "con_count 34000, traindata_count 72632\n",
      "con_count 35000, traindata_count 75087\n",
      "con_count 36000, traindata_count 77276\n",
      "con_count 37000, traindata_count 79020\n",
      "con_count 38000, traindata_count 81055\n",
      "con_count 39000, traindata_count 83212\n",
      "con_count 40000, traindata_count 85462\n",
      "con_count 41000, traindata_count 87717\n",
      "con_count 42000, traindata_count 90933\n",
      "con_count 43000, traindata_count 93730\n",
      "con_count 44000, traindata_count 95726\n",
      "con_count 45000, traindata_count 97907\n",
      "con_count 46000, traindata_count 100056\n",
      "con_count 47000, traindata_count 102594\n",
      "con_count 48000, traindata_count 104500\n",
      "con_count 49000, traindata_count 106753\n",
      "con_count 50000, traindata_count 108974\n",
      "con_count 51000, traindata_count 111087\n",
      "con_count 52000, traindata_count 113508\n",
      "con_count 53000, traindata_count 115709\n",
      "con_count 54000, traindata_count 117896\n",
      "con_count 55000, traindata_count 119670\n",
      "con_count 56000, traindata_count 121593\n",
      "con_count 57000, traindata_count 123375\n",
      "con_count 58000, traindata_count 125332\n",
      "con_count 59000, traindata_count 127916\n",
      "con_count 60000, traindata_count 130063\n",
      "con_count 61000, traindata_count 132035\n",
      "con_count 62000, traindata_count 134442\n",
      "con_count 63000, traindata_count 136628\n",
      "con_count 64000, traindata_count 138860\n",
      "con_count 65000, traindata_count 140717\n",
      "con_count 66000, traindata_count 143000\n",
      "con_count 67000, traindata_count 145005\n",
      "con_count 68000, traindata_count 147070\n",
      "con_count 69000, traindata_count 149109\n",
      "con_count 70000, traindata_count 151472\n",
      "con_count 71000, traindata_count 153787\n",
      "con_count 72000, traindata_count 155705\n",
      "con_count 73000, traindata_count 157753\n",
      "con_count 74000, traindata_count 160029\n",
      "con_count 75000, traindata_count 162029\n",
      "con_count 76000, traindata_count 164162\n",
      "con_count 77000, traindata_count 166159\n",
      "con_count 78000, traindata_count 168425\n",
      "con_count 79000, traindata_count 170328\n",
      "con_count 80000, traindata_count 172567\n",
      "con_count 81000, traindata_count 174927\n",
      "con_count 82000, traindata_count 176857\n",
      "con_count 83000, traindata_count 178575\n",
      "Time Elapsed: 3.2952635288238525 secs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import _pickle as pickle\n",
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "from gensim.models import word2vec, KeyedVectors\n",
    "\n",
    "WORD_VECTOR_SIZE = 300\n",
    "\n",
    "raw_movie_conversations = open('data/movie_conversations.txt', 'r').read().split('\\n')[:-1]\n",
    "\n",
    "utterance_dict = pickle.load(open('data/utterance_dict', 'rb'))\n",
    "\n",
    "ts = time.time()\n",
    "corpus = word2vec.Text8Corpus(\"data/tokenized_all_words.txt\")\n",
    "word_vector = word2vec.Word2Vec(corpus, size=WORD_VECTOR_SIZE)\n",
    "word_vector.wv.save_word2vec_format(u\"model/word_vector.bin\", binary=True)\n",
    "word_vector = KeyedVectors.load_word2vec_format('model/word_vector.bin', binary=True)\n",
    "print(\"Time Elapsed: {} secs\\n\".format(time.time() - ts))\n",
    "\n",
    "\"\"\" Extract only the vocabulary part of the data \"\"\"\n",
    "def refine(data):\n",
    "    words = re.findall(\"[a-zA-Z'-]+\", data)\n",
    "    words = [\"\".join(word.split(\"'\")) for word in words]\n",
    "    # words = [\"\".join(word.split(\"-\")) for word in words]\n",
    "    data = ' '.join(words)\n",
    "    return data\n",
    "\n",
    "ts = time.time()\n",
    "conversations = []\n",
    "print('len conversation', len(raw_movie_conversations))\n",
    "con_count = 0\n",
    "traindata_count = 0\n",
    "for conversation in raw_movie_conversations:\n",
    "    conversation = conversation.split(' +++$+++ ')[-1]\n",
    "    conversation = conversation.replace('[', '')\n",
    "    conversation = conversation.replace(']', '')\n",
    "    conversation = conversation.replace('\\'', '')\n",
    "    conversation = conversation.split(', ')\n",
    "    assert len(conversation) > 1\n",
    "    for i in range(len(conversation)-1):\n",
    "        con_a = utterance_dict[conversation[i+1]].strip()\n",
    "        con_b = utterance_dict[conversation[i]].strip()\n",
    "        if len(con_a.split()) <= 22 and len(con_b.split()) <= 22:\n",
    "            con_a = [refine(w) for w in con_a.lower().split()]\n",
    "            # con_a = [word_vector[w] if w in word_vector else np.zeros(WORD_VECTOR_SIZE) for w in con_a]\n",
    "            conversations.append((con_a, con_b))\n",
    "            traindata_count += 1\n",
    "    con_count += 1\n",
    "    if con_count % 1000 == 0:\n",
    "        print('con_count {}, traindata_count {}'.format(con_count, traindata_count))\n",
    "pickle.dump(conversations, open('data/reversed_conversations_lenmax22', 'wb'), True)\n",
    "print(\"Time Elapsed: {} secs\\n\".format(time.time() - ts))\n",
    "\n",
    "# some statistics of training data\n",
    "max_a = -1\n",
    "max_b = -1\n",
    "max_a_ind = -1\n",
    "max_b_ind = -1\n",
    "sum_a = 0.\n",
    "sum_b = 0.\n",
    "len_a_list = []\n",
    "len_b_list = []\n",
    "for i in range(len(conversations)):\n",
    "    len_a = len(conversations[i][0])\n",
    "    len_b = len(conversations[i][1].split())\n",
    "    if len_a > max_a:\n",
    "        max_a = len_a\n",
    "        max_a_ind = i\n",
    "    if len_b > max_b:\n",
    "        max_b = len_b\n",
    "        max_b_ind = i\n",
    "    sum_a += len_a\n",
    "    sum_b += len_b\n",
    "    len_a_list.append(len_a)\n",
    "    len_b_list.append(len_b)\n",
    "np.save(\"data/reversed_lenmax22_a_list\", np.array(len_a_list))\n",
    "np.save(\"data/reversed_lenmax22_b_list\", np.array(len_b_list))\n",
    "print(\"max_a_ind {}, max_b_ind {}\".format(max_a_ind, max_b_ind))\n",
    "print(\"max_a {}, max_b {}, avg_a {}, avg_b {}\".format(max_a, max_b, sum_a/len(conversations), sum_b/len(conversations)))\n",
    "\n",
    "ts = time.time()\n",
    "conversations = []\n",
    "# former_sents = []\n",
    "print('len conversation', len(raw_movie_conversations))\n",
    "con_count = 0\n",
    "traindata_count = 0\n",
    "for conversation in raw_movie_conversations:\n",
    "    conversation = conversation.split(' +++$+++ ')[-1]\n",
    "    conversation = conversation.replace('[', '')\n",
    "    conversation = conversation.replace(']', '')\n",
    "    conversation = conversation.replace('\\'', '')\n",
    "    conversation = conversation.split(', ')\n",
    "    assert len(conversation) > 1\n",
    "    con_a_1 = ''\n",
    "    for i in range(len(conversation)-1):\n",
    "        con_a_2 = utterance_dict[conversation[i]]\n",
    "        con_b = utterance_dict[conversation[i+1]]\n",
    "        if len(con_a_1.split()) <= 22 and len(con_a_2.split()) <= 22 and len(con_b.split()) <= 22:\n",
    "            con_a = \"{} {}\".format(con_a_1, con_a_2)\n",
    "            con_a = [refine(w) for w in con_a.lower().split()]\n",
    "            # con_a = [word_vector[w] if w in word_vector else np.zeros(WORD_VECTOR_SIZE) for w in con_a]\n",
    "            conversations.append((con_a, con_b, con_a_2))\n",
    "            # former_sents.append(con_a_2)\n",
    "            traindata_count += 1\n",
    "        con_a_1 = con_a_2\n",
    "    con_count += 1\n",
    "    if con_count % 1000 == 0:\n",
    "        print('con_count {}, traindata_count {}'.format(con_count, traindata_count))\n",
    "pickle.dump(conversations, open('data/conversations_lenmax22_formersents2_with_former', 'wb'), True)\n",
    "# pickle.dump(former_sents, open('data/conversations_lenmax22_former_sents', 'wb'), True)\n",
    "print(\"Time Elapsed: {} secs\\n\".format(time.time() - ts))\n",
    "\n",
    "ts = time.time()\n",
    "conversations = []\n",
    "# former_sents = []\n",
    "print('len conversation', len(raw_movie_conversations))\n",
    "con_count = 0\n",
    "traindata_count = 0\n",
    "for conversation in raw_movie_conversations:\n",
    "    conversation = conversation.split(' +++$+++ ')[-1]\n",
    "    conversation = conversation.replace('[', '')\n",
    "    conversation = conversation.replace(']', '')\n",
    "    conversation = conversation.replace('\\'', '')\n",
    "    conversation = conversation.split(', ')\n",
    "    assert len(conversation) > 1\n",
    "    con_a_1 = ''\n",
    "    for i in range(len(conversation)-1):\n",
    "        con_a_2 = utterance_dict[conversation[i]]\n",
    "        con_b = utterance_dict[conversation[i+1]]\n",
    "        if len(con_a_1.split()) <= 22 and len(con_a_2.split()) <= 22 and len(con_b.split()) <= 22:\n",
    "            con_a = \"{} {}\".format(con_a_1, con_a_2)\n",
    "            con_a = [refine(w) for w in con_a.lower().split()]\n",
    "            # con_a = [word_vector[w] if w in word_vector else np.zeros(WORD_VECTOR_SIZE) for w in con_a]\n",
    "            conversations.append((con_a, con_b))\n",
    "            # former_sents.append(con_a_2)\n",
    "            traindata_count += 1\n",
    "        con_a_1 = con_a_2\n",
    "    con_count += 1\n",
    "    if con_count % 1000 == 0:\n",
    "        print('con_count {}, traindata_count {}'.format(con_count, traindata_count))\n",
    "pickle.dump(conversations, open('data/conversations_lenmax22_former_sents2', 'wb'), True)\n",
    "print(\"Time Elapsed: {} secs\\n\".format(time.time() - ts))\n",
    "\n",
    "ts = time.time()\n",
    "conversations = []\n",
    "print('len conversation', len(raw_movie_conversations))\n",
    "con_count = 0\n",
    "traindata_count = 0\n",
    "for conversation in raw_movie_conversations:\n",
    "    conversation = conversation.split(' +++$+++ ')[-1]\n",
    "    conversation = conversation.replace('[', '')\n",
    "    conversation = conversation.replace(']', '')\n",
    "    conversation = conversation.replace('\\'', '')\n",
    "    conversation = conversation.split(', ')\n",
    "    assert len(conversation) > 1\n",
    "    for i in range(len(conversation)-1):\n",
    "        con_a = utterance_dict[conversation[i]]\n",
    "        con_b = utterance_dict[conversation[i+1]]\n",
    "        if len(con_a.split()) <= 22 and len(con_b.split()) <= 22:\n",
    "            con_a = [refine(w) for w in con_a.lower().split()]\n",
    "            # con_a = [word_vector[w] if w in word_vector else np.zeros(WORD_VECTOR_SIZE) for w in con_a]\n",
    "            conversations.append((con_a, con_b))\n",
    "            traindata_count += 1\n",
    "    con_count += 1\n",
    "    if con_count % 1000 == 0:\n",
    "        print('con_count {}, traindata_count {}'.format(con_count, traindata_count))\n",
    "pickle.dump(conversations, open('data/conversations_lenmax22', 'wb'), True)\n",
    "print(\"Time Elapsed: {} secs\\n\".format(time.time() - ts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _pickle as Pickle\n",
    "import random\n",
    "\n",
    "class Data_Reader:\n",
    "    def __init__(self, cur_train_index=0, load_list=False):\n",
    "        self.training_data = pickle.load(open(config.training_data_path, 'rb'))\n",
    "        self.data_size = len(self.training_data)\n",
    "        if load_list:\n",
    "            self.shuffle_list = pickle.load(open(config.index_list_file, 'rb'))\n",
    "        else:    \n",
    "            self.shuffle_list = self.shuffle_index()\n",
    "        self.train_index = cur_train_index\n",
    "\n",
    "    def get_batch_num(self, batch_size):\n",
    "        return self.data_size // batch_size\n",
    "\n",
    "    def shuffle_index(self):\n",
    "        shuffle_index_list = random.sample(range(self.data_size), self.data_size)\n",
    "        pickle.dump(shuffle_index_list, open(config.index_list_file, 'wb'), True)\n",
    "        return shuffle_index_list\n",
    "\n",
    "    def generate_batch_index(self, batch_size):\n",
    "        if self.train_index + batch_size > self.data_size:\n",
    "            batch_index = self.shuffle_list[self.train_index:self.data_size]\n",
    "            self.shuffle_list = self.shuffle_index()\n",
    "            remain_size = batch_size - (self.data_size - self.train_index)\n",
    "            batch_index += self.shuffle_list[:remain_size]\n",
    "            self.train_index = remain_size\n",
    "        else:\n",
    "            batch_index = self.shuffle_list[self.train_index:self.train_index+batch_size]\n",
    "            self.train_index += batch_size\n",
    "\n",
    "        return batch_index\n",
    "\n",
    "    def generate_training_batch(self, batch_size):\n",
    "        batch_index = self.generate_batch_index(batch_size)\n",
    "        batch_X = [self.training_data[i][0] for i in batch_index]   # batch_size of conv_a\n",
    "        batch_Y = [self.training_data[i][1] for i in batch_index]   # batch_size of conv_b\n",
    "\n",
    "        return batch_X, batch_Y\n",
    "\n",
    "    def generate_training_batch_with_former(self, batch_size):\n",
    "        batch_index = self.generate_batch_index(batch_size)\n",
    "        batch_X = [self.training_data[i][0] for i in batch_index]   # batch_size of conv_a\n",
    "        batch_Y = [self.training_data[i][1] for i in batch_index]   # batch_size of conv_b\n",
    "        former = [self.training_data[i][2] for i in batch_index]    # batch_size of former utterance\n",
    "\n",
    "        return batch_X, batch_Y, former\n",
    "\n",
    "    def generate_testing_batch(self, batch_size):\n",
    "        batch_index = self.generate_batch_index(batch_size)\n",
    "        batch_X = [self.training_data[i][0] for i in batch_index]   # batch_size of conv_a\n",
    "\n",
    "        return batch_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import codecs\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def preProBuildWordVocab(word_count_threshold=5, all_words_path=config.all_words_path):\n",
    "    # borrowed this function from NeuralTalk\n",
    "\n",
    "    if not os.path.exists(all_words_path):\n",
    "        parse_all_words(all_words_path)\n",
    "\n",
    "    corpus = open(all_words_path, 'r').read().split('\\n')[:-1]\n",
    "    captions = np.asarray(corpus, dtype=np.object)\n",
    "\n",
    "    captions = map(lambda x: x.replace('.', ''), captions)\n",
    "    captions = map(lambda x: x.replace(',', ''), captions)\n",
    "    captions = map(lambda x: x.replace('\"', ''), captions)\n",
    "    captions = map(lambda x: x.replace('\\n', ''), captions)\n",
    "    captions = map(lambda x: x.replace('?', ''), captions)\n",
    "    captions = map(lambda x: x.replace('!', ''), captions)\n",
    "    captions = map(lambda x: x.replace('\\\\', ''), captions)\n",
    "    captions = map(lambda x: x.replace('/', ''), captions)\n",
    "\n",
    "    print('preprocessing word counts and creating vocab based on word count threshold %d' % (word_count_threshold))\n",
    "    word_counts = {}\n",
    "    nsents = 0\n",
    "    for sent in captions:\n",
    "        nsents += 1\n",
    "        for w in sent.lower().split(' '):\n",
    "           word_counts[w] = word_counts.get(w, 0) + 1\n",
    "    vocab = [w for w in word_counts if word_counts[w] >= word_count_threshold]\n",
    "    print('filtered words from %d to %d' % (len(word_counts), len(vocab)))\n",
    "\n",
    "    ixtoword = {}\n",
    "    ixtoword[0] = '<pad>'\n",
    "    ixtoword[1] = '<bos>'\n",
    "    ixtoword[2] = '<eos>'\n",
    "    ixtoword[3] = '<unk>'\n",
    "\n",
    "    wordtoix = {}\n",
    "    wordtoix['<pad>'] = 0\n",
    "    wordtoix['<bos>'] = 1\n",
    "    wordtoix['<eos>'] = 2\n",
    "    wordtoix['<unk>'] = 3\n",
    "\n",
    "    for idx, w in enumerate(vocab):\n",
    "        wordtoix[w] = idx+4\n",
    "        ixtoword[idx+4] = w\n",
    "\n",
    "    word_counts['<pad>'] = nsents\n",
    "    word_counts['<bos>'] = nsents\n",
    "    word_counts['<eos>'] = nsents\n",
    "    word_counts['<unk>'] = nsents\n",
    "\n",
    "    bias_init_vector = np.array([1.0 * word_counts[ixtoword[i]] for i in ixtoword])\n",
    "    bias_init_vector /= np.sum(bias_init_vector) # normalize to frequencies\n",
    "    bias_init_vector = np.log(bias_init_vector)\n",
    "    bias_init_vector -= np.max(bias_init_vector) # shift to nice numeric range\n",
    "\n",
    "    return wordtoix, ixtoword, bias_init_vector\n",
    "\n",
    "def parse_all_words(all_words_path):\n",
    "    raw_movie_lines = open('data/all_words.txt', 'r', encoding='utf-8', errors='ignore').read().split('\\n')[:-1]\n",
    "\n",
    "    with codecs.open(all_words_path, \"w\", encoding='utf-8', errors='ignore') as f:\n",
    "        for line in raw_movie_lines:\n",
    "            line = line.split(' +++$+++ ')\n",
    "            utterance = line[-1]\n",
    "            f.write(utterance + '\\n')\n",
    "\n",
    "\"\"\" Extract only the vocabulary part of the data \"\"\"\n",
    "def refine(data):\n",
    "    words = re.findall(\"[a-zA-Z'-]+\", data)\n",
    "    words = [\"\".join(word.split(\"'\")) for word in words]\n",
    "    # words = [\"\".join(word.split(\"-\")) for word in words]\n",
    "    data = ' '.join(words)\n",
    "    return data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parse_all_words(config.all_words_path)\n",
    "\n",
    "    raw_movie_lines = open('data/movie_lines.txt', 'r', encoding='utf-8', errors='ignore').read().split('\\n')[:-1]\n",
    "    \n",
    "    utterance_dict = {}\n",
    "    with codecs.open('data/tokenized_all_words.txt', \"w\", encoding='utf-8', errors='ignore') as f:\n",
    "        for line in raw_movie_lines:\n",
    "            line = line.split(' +++$+++ ')\n",
    "            line_ID = line[0]\n",
    "            utterance = line[-1]\n",
    "            utterance_dict[line_ID] = utterance\n",
    "            utterance = \" \".join([refine(w) for w in utterance.lower().split()])\n",
    "            f.write(utterance + '\\n')\n",
    "    pickle.dump(utterance_dict, open('data/utterance_dict', 'wb'), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class Seq2Seq_chatbot():\n",
    "    def __init__(self, dim_wordvec, n_words, dim_hidden, batch_size, n_encode_lstm_step, n_decode_lstm_step, bias_init_vector=None, lr=0.0001):\n",
    "        self.dim_wordvec = dim_wordvec\n",
    "        self.dim_hidden = dim_hidden\n",
    "        self.batch_size = batch_size\n",
    "        self.n_words = n_words\n",
    "        self.n_encode_lstm_step = n_encode_lstm_step\n",
    "        self.n_decode_lstm_step = n_decode_lstm_step\n",
    "        self.lr = lr\n",
    "\n",
    "        with tf.device(\"/cpu:0\"):\n",
    "            self.Wemb = tf.Variable(tf.random_uniform([n_words, dim_hidden], -0.1, 0.1), name='Wemb')\n",
    "\n",
    "        self.lstm1 = tf.contrib.rnn.BasicLSTMCell(dim_hidden, state_is_tuple=False)\n",
    "        self.lstm2 = tf.contrib.rnn.BasicLSTMCell(dim_hidden, state_is_tuple=False)\n",
    "\n",
    "        self.encode_vector_W = tf.Variable(tf.random_uniform([dim_wordvec, dim_hidden], -0.1, 0.1), name='encode_vector_W')\n",
    "        self.encode_vector_b = tf.Variable(tf.zeros([dim_hidden]), name='encode_vector_b')\n",
    "\n",
    "        self.embed_word_W = tf.Variable(tf.random_uniform([dim_hidden, n_words], -0.1, 0.1), name='embed_word_W')\n",
    "        if bias_init_vector is not None:\n",
    "            self.embed_word_b = tf.Variable(bias_init_vector.astype(np.float32), name='embed_word_b')\n",
    "        else:\n",
    "            self.embed_word_b = tf.Variable(tf.zeros([n_words]), name='embed_word_b')\n",
    "\n",
    "    def build_model(self):\n",
    "        word_vectors = tf.placeholder(tf.float32, [self.batch_size, self.n_encode_lstm_step, self.dim_wordvec])\n",
    "\n",
    "        caption = tf.placeholder(tf.int32, [self.batch_size, self.n_decode_lstm_step+1])\n",
    "        caption_mask = tf.placeholder(tf.float32, [self.batch_size, self.n_decode_lstm_step+1])\n",
    "\n",
    "        word_vectors_flat = tf.reshape(word_vectors, [-1, self.dim_wordvec])\n",
    "        wordvec_emb = tf.nn.xw_plus_b(word_vectors_flat, self.encode_vector_W, self.encode_vector_b ) # (batch_size*n_encode_lstm_step, dim_hidden)\n",
    "        wordvec_emb = tf.reshape(wordvec_emb, [self.batch_size, self.n_encode_lstm_step, self.dim_hidden])\n",
    "\n",
    "        state1 = tf.zeros([self.batch_size, self.lstm1.state_size])\n",
    "        state2 = tf.zeros([self.batch_size, self.lstm2.state_size])\n",
    "        padding = tf.zeros([self.batch_size, self.dim_hidden])\n",
    "\n",
    "        probs = []\n",
    "        entropies = []\n",
    "        loss = 0.0\n",
    "\n",
    "        ##############################  Encoding Stage ##################################\n",
    "        for i in range(0, self.n_encode_lstm_step):\n",
    "            if i > 0:\n",
    "                tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "            with tf.variable_scope(\"LSTM1\"):\n",
    "                output1, state1 = self.lstm1(wordvec_emb[:, i, :], state1)\n",
    "\n",
    "            with tf.variable_scope(\"LSTM2\"):\n",
    "                output2, state2 = self.lstm2(tf.concat([padding, output1], 1), state2)\n",
    "\n",
    "        ############################# Decoding Stage ######################################\n",
    "        for i in range(0, self.n_decode_lstm_step):\n",
    "            with tf.device(\"/cpu:0\"):\n",
    "                current_embed = tf.nn.embedding_lookup(self.Wemb, caption[:, i])\n",
    "\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "            with tf.variable_scope(\"LSTM1\"):\n",
    "                output1, state1 = self.lstm1(padding, state1)\n",
    "\n",
    "            with tf.variable_scope(\"LSTM2\"):\n",
    "                output2, state2 = self.lstm2(tf.concat([current_embed, output1], 1), state2)\n",
    "\n",
    "            labels = tf.expand_dims(caption[:, i+1], 1)\n",
    "            indices = tf.expand_dims(tf.range(0, self.batch_size, 1), 1)\n",
    "            concated = tf.concat([indices, labels], 1)\n",
    "            onehot_labels = tf.sparse_to_dense(concated, tf.stack([self.batch_size, self.n_words]), 1.0, 0.0)\n",
    "\n",
    "            logit_words = tf.nn.xw_plus_b(output2, self.embed_word_W, self.embed_word_b)\n",
    "            cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logit_words, labels=onehot_labels)\n",
    "            cross_entropy = cross_entropy * caption_mask[:, i]\n",
    "            entropies.append(cross_entropy)\n",
    "            probs.append(logit_words)\n",
    "\n",
    "            current_loss = tf.reduce_sum(cross_entropy)/self.batch_size\n",
    "            loss = loss + current_loss\n",
    "\n",
    "        with tf.variable_scope(tf.get_variable_scope(), reuse=False):\n",
    "            train_op = tf.train.GradientDescentOptimizer(self.lr).minimize(loss)\n",
    "\n",
    "        inter_value = {\n",
    "            'probs': probs,\n",
    "            'entropies': entropies\n",
    "        }\n",
    "\n",
    "        return train_op, loss, word_vectors, caption, caption_mask, inter_value\n",
    "\n",
    "    def build_generator(self):\n",
    "        word_vectors = tf.placeholder(tf.float32, [1, self.n_encode_lstm_step, self.dim_wordvec])\n",
    "\n",
    "        word_vectors_flat = tf.reshape(word_vectors, [-1, self.dim_wordvec])\n",
    "        wordvec_emb = tf.nn.xw_plus_b(word_vectors_flat, self.encode_vector_W, self.encode_vector_b)\n",
    "        wordvec_emb = tf.reshape(wordvec_emb, [1, self.n_encode_lstm_step, self.dim_hidden])\n",
    "\n",
    "        state1 = tf.zeros([1, self.lstm1.state_size])\n",
    "        state2 = tf.zeros([1, self.lstm2.state_size])\n",
    "        padding = tf.zeros([1, self.dim_hidden])\n",
    "\n",
    "        generated_words = []\n",
    "\n",
    "        probs = []\n",
    "        embeds = []\n",
    "\n",
    "        for i in range(0, self.n_encode_lstm_step):\n",
    "            if i > 0:\n",
    "                tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "            with tf.variable_scope(\"LSTM1\"):\n",
    "                output1, state1 = self.lstm1(wordvec_emb[:, i, :], state1)\n",
    "\n",
    "            with tf.variable_scope(\"LSTM2\"):\n",
    "                output2, state2 = self.lstm2(tf.concat([padding, output1], 1), state2)\n",
    "\n",
    "        for i in range(0, self.n_decode_lstm_step):\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "            if i == 0:\n",
    "                with tf.device('/cpu:0'):\n",
    "                    current_embed = tf.nn.embedding_lookup(self.Wemb, tf.ones([1], dtype=tf.int64))\n",
    "\n",
    "            with tf.variable_scope(\"LSTM1\"):\n",
    "                output1, state1 = self.lstm1(padding, state1)\n",
    "\n",
    "            with tf.variable_scope(\"LSTM2\"):\n",
    "                output2, state2 = self.lstm2(tf.concat([current_embed, output1], 1), state2)\n",
    "\n",
    "            logit_words = tf.nn.xw_plus_b(output2, self.embed_word_W, self.embed_word_b)\n",
    "            max_prob_index = tf.argmax(logit_words, 1)[0]\n",
    "            generated_words.append(max_prob_index)\n",
    "            probs.append(logit_words)\n",
    "\n",
    "            with tf.device(\"/cpu:0\"):\n",
    "                current_embed = tf.nn.embedding_lookup(self.Wemb, max_prob_index)\n",
    "                current_embed = tf.expand_dims(current_embed, 0)\n",
    "\n",
    "            embeds.append(current_embed)\n",
    "\n",
    "        return word_vectors, generated_words, probs, embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class Seq2Seq_chatbot():\n",
    "    def __init__(self, dim_wordvec, n_words, dim_hidden, batch_size, n_encode_lstm_step, n_decode_lstm_step, bias_init_vector=None, lr=0.0001):\n",
    "        self.dim_wordvec = dim_wordvec\n",
    "        self.dim_hidden = dim_hidden\n",
    "        self.batch_size = batch_size\n",
    "        self.n_words = n_words\n",
    "        self.n_encode_lstm_step = n_encode_lstm_step\n",
    "        self.n_decode_lstm_step = n_decode_lstm_step\n",
    "        self.lr = lr\n",
    "\n",
    "        with tf.device(\"/cpu:0\"):\n",
    "            self.Wemb = tf.Variable(tf.random_uniform([n_words, dim_hidden], -0.1, 0.1), name='Wemb')\n",
    "\n",
    "        self.lstm1 = tf.contrib.rnn.BasicLSTMCell(dim_hidden, state_is_tuple=False)\n",
    "        self.lstm2 = tf.contrib.rnn.BasicLSTMCell(dim_hidden, state_is_tuple=False)\n",
    "\n",
    "        self.encode_vector_W = tf.Variable(tf.random_uniform([dim_wordvec, dim_hidden], -0.1, 0.1), name='encode_vector_W')\n",
    "        self.encode_vector_b = tf.Variable(tf.zeros([dim_hidden]), name='encode_vector_b')\n",
    "\n",
    "        self.embed_word_W = tf.Variable(tf.random_uniform([dim_hidden, n_words], -0.1, 0.1), name='embed_word_W')\n",
    "        if bias_init_vector is not None:\n",
    "            self.embed_word_b = tf.Variable(bias_init_vector.astype(np.float32), name='embed_word_b')\n",
    "        else:\n",
    "            self.embed_word_b = tf.Variable(tf.zeros([n_words]), name='embed_word_b')\n",
    "\n",
    "    def build_model(self):\n",
    "        word_vectors = tf.placeholder(tf.float32, [self.batch_size, self.n_encode_lstm_step, self.dim_wordvec])\n",
    "\n",
    "        caption = tf.placeholder(tf.int32, [self.batch_size, self.n_decode_lstm_step+1])\n",
    "        caption_mask = tf.placeholder(tf.float32, [self.batch_size, self.n_decode_lstm_step+1])\n",
    "\n",
    "        word_vectors_flat = tf.reshape(word_vectors, [-1, self.dim_wordvec])\n",
    "        wordvec_emb = tf.nn.xw_plus_b(word_vectors_flat, self.encode_vector_W, self.encode_vector_b ) # (batch_size*n_encode_lstm_step, dim_hidden)\n",
    "        wordvec_emb = tf.reshape(wordvec_emb, [self.batch_size, self.n_encode_lstm_step, self.dim_hidden])\n",
    "\n",
    "        state1 = tf.zeros([self.batch_size, self.lstm1.state_size])\n",
    "        state2 = tf.zeros([self.batch_size, self.lstm2.state_size])\n",
    "        padding = tf.zeros([self.batch_size, self.dim_hidden])\n",
    "\n",
    "        probs = []\n",
    "        entropies = []\n",
    "        loss = 0.0\n",
    "\n",
    "        ##############################  Encoding Stage ##################################\n",
    "        for i in range(0, self.n_encode_lstm_step):\n",
    "            if i > 0:\n",
    "                tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "            with tf.variable_scope(\"LSTM1\"):\n",
    "                output1, state1 = self.lstm1(wordvec_emb[:, i, :], state1)\n",
    "\n",
    "            with tf.variable_scope(\"LSTM2\"):\n",
    "                output2, state2 = self.lstm2(tf.concat([padding, output1], 1), state2)\n",
    "\n",
    "        ############################# Decoding Stage ######################################\n",
    "        for i in range(0, self.n_decode_lstm_step):\n",
    "            with tf.device(\"/cpu:0\"):\n",
    "                current_embed = tf.nn.embedding_lookup(self.Wemb, caption[:, i])\n",
    "\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "            with tf.variable_scope(\"LSTM1\"):\n",
    "                output1, state1 = self.lstm1(padding, state1)\n",
    "\n",
    "            with tf.variable_scope(\"LSTM2\"):\n",
    "                output2, state2 = self.lstm2(tf.concat([current_embed, output1], 1), state2)\n",
    "\n",
    "            labels = tf.expand_dims(caption[:, i+1], 1)\n",
    "            indices = tf.expand_dims(tf.range(0, self.batch_size, 1), 1)\n",
    "            concated = tf.concat([indices, labels], 1)\n",
    "            onehot_labels = tf.sparse_to_dense(concated, tf.stack([self.batch_size, self.n_words]), 1.0, 0.0)\n",
    "\n",
    "            logit_words = tf.nn.xw_plus_b(output2, self.embed_word_W, self.embed_word_b)\n",
    "            cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logit_words, labels=onehot_labels)\n",
    "            cross_entropy = cross_entropy * caption_mask[:, i]\n",
    "            entropies.append(cross_entropy)\n",
    "            probs.append(logit_words)\n",
    "\n",
    "            current_loss = tf.math.reduce_sum(cross_entropy)/self.batch_size\n",
    "            #print(\"the current loss is\", current_loss)\n",
    "            loss = loss + current_loss\n",
    "            #print(\"Overall loss is\", loss)\n",
    "\n",
    "        with tf.variable_scope(tf.get_variable_scope(), reuse=tf.AUTO_REUSE):\n",
    "            train_op = tf.train.AdamOptimizer(self.lr).minimize(loss=current_loss)\n",
    "\n",
    "        inter_value = {\n",
    "            'probs': probs,\n",
    "            'entropies': entropies\n",
    "        }\n",
    "\n",
    "        return train_op, loss, word_vectors, caption, caption_mask, inter_value\n",
    "\n",
    "    def build_generator(self):\n",
    "        word_vectors = tf.placeholder(tf.float32, [1, self.n_encode_lstm_step, self.dim_wordvec])\n",
    "\n",
    "        word_vectors_flat = tf.reshape(word_vectors, [-1, self.dim_wordvec])\n",
    "        wordvec_emb = tf.nn.xw_plus_b(word_vectors_flat, self.encode_vector_W, self.encode_vector_b)\n",
    "        wordvec_emb = tf.reshape(wordvec_emb, [1, self.n_encode_lstm_step, self.dim_hidden])\n",
    "\n",
    "        state1 = tf.zeros([1, self.lstm1.state_size])\n",
    "        state2 = tf.zeros([1, self.lstm2.state_size])\n",
    "        padding = tf.zeros([1, self.dim_hidden])\n",
    "\n",
    "        generated_words = []\n",
    "\n",
    "        probs = []\n",
    "        embeds = []\n",
    "\n",
    "        for i in range(0, self.n_encode_lstm_step):\n",
    "            if i > 0:\n",
    "                tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "            with tf.variable_scope(\"LSTM1\"):\n",
    "                output1, state1 = self.lstm1(wordvec_emb[:, i, :], state1)\n",
    "\n",
    "            with tf.variable_scope(\"LSTM2\"):\n",
    "                output2, state2 = self.lstm2(tf.concat([padding, output1], 1), state2)\n",
    "\n",
    "        for i in range(0, self.n_decode_lstm_step):\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "            if i == 0:\n",
    "                with tf.device('/cpu:0'):\n",
    "                    current_embed = tf.nn.embedding_lookup(self.Wemb, tf.ones([1], dtype=tf.int64))\n",
    "\n",
    "            with tf.variable_scope(\"LSTM1\"):\n",
    "                output1, state1 = self.lstm1(padding, state1)\n",
    "\n",
    "            with tf.variable_scope(\"LSTM2\"):\n",
    "                output2, state2 = self.lstm2(tf.concat([current_embed, output1], 1), state2)\n",
    "\n",
    "            logit_words = tf.nn.xw_plus_b(output2, self.embed_word_W, self.embed_word_b)\n",
    "            max_prob_index = tf.argmax(logit_words, 1)[0]\n",
    "            generated_words.append(max_prob_index)\n",
    "            probs.append(logit_words)\n",
    "\n",
    "            with tf.device(\"/cpu:0\"):\n",
    "                current_embed = tf.nn.embedding_lookup(self.Wemb, max_prob_index)\n",
    "                current_embed = tf.expand_dims(current_embed, 0)\n",
    "\n",
    "            embeds.append(current_embed)\n",
    "\n",
    "        return word_vectors, generated_words, probs, embeds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing word counts and creating vocab based on word count threshold 20\n",
      "filtered words from 76029 to 6847\n",
      "300 6851 1000 100 44 22 [ 0.          0.          0.         ... -9.4490718  -9.58260319\n",
      " -9.4490718 ] 0.0001\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000001C70643FAC8>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n",
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell_impl.BasicLSTMCell object at 0x000001C709C465C0>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'gradients_4/LSTM2_264/basic_lstm_cell/Add_44_grad/Sum'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-4b978a70b3a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-29-4b978a70b3a7>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     89\u001b[0m             lr=learning_rate)\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m     \u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_vectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf_caption\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf_caption_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minter_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[0msaver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_to_keep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-fd2b3e563fea>\u001b[0m in \u001b[0;36mbuild_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_variable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[0mtrain_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurrent_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         inter_value = {\n",
      "\u001b[1;32m~\\Anaconda2_64\\envs\\HIRA\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[0maggregation_method\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation_method\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m         grad_loss=grad_loss)\n\u001b[0m\u001b[0;32m    401\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m     \u001b[0mvars_with_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mg\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2_64\\envs\\HIRA\\lib\\site-packages\\tensorflow\\python\\training\\optimizer.py\u001b[0m in \u001b[0;36mcompute_gradients\u001b[1;34m(self, loss, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, grad_loss)\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[0mgate_gradients\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgate_gradients\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGATE_OP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[0maggregation_method\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maggregation_method\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m         colocate_gradients_with_ops=colocate_gradients_with_ops)\n\u001b[0m\u001b[0;32m    520\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mgate_gradients\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGATE_GRAPH\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m       \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontrol_flow_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2_64\\envs\\HIRA\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\u001b[0m in \u001b[0;36mgradients\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients)\u001b[0m\n\u001b[0;32m    628\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m     return _GradientsHelper(ys, xs, grad_ys, name, colocate_gradients_with_ops,\n\u001b[1;32m--> 630\u001b[1;33m                             gate_gradients, aggregation_method, stop_gradients)\n\u001b[0m\u001b[0;32m    631\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2_64\\envs\\HIRA\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, src_graph)\u001b[0m\n\u001b[0;32m    696\u001b[0m     \u001b[0mstop_gradient_ops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstop_gradients\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    697\u001b[0m     reachable_to_ops, pending_count, loop_state = _PendingCount(\n\u001b[1;32m--> 698\u001b[1;33m         to_ops, from_ops, colocate_gradients_with_ops, func_graphs, xs)\n\u001b[0m\u001b[0;32m    699\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m     \u001b[1;31m# Iterate over the collected ops.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2_64\\envs\\HIRA\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\u001b[0m in \u001b[0;36m_PendingCount\u001b[1;34m(to_ops, from_ops, colocate_gradients_with_ops, func_graphs, xs)\u001b[0m\n\u001b[0;32m    166\u001b[0m   \u001b[1;31m# Mark reachable ops from from_ops.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m   \u001b[0mreached_ops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m   \u001b[0m_MarkReachedOps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfrom_ops\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreached_ops\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc_graphs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m   \u001b[1;31m# X in reached_ops iff X is reachable from from_ops by a path of zero or more\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m   \u001b[1;31m# backpropagatable tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2_64\\envs\\HIRA\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\u001b[0m in \u001b[0;36m_MarkReachedOps\u001b[1;34m(from_ops, reached_ops, func_graphs)\u001b[0m\n\u001b[0;32m    137\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_IsBackpropagatable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m           \u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_Consumers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc_graphs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2_64\\envs\\HIRA\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\u001b[0m in \u001b[0;36m_Consumers\u001b[1;34m(t, func_graphs)\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[0mfunc_graphs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m   \"\"\"\n\u001b[1;32m--> 532\u001b[1;33m   \u001b[0mconsumers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconsumers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfunc_graphs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0minput_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplaceholder\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_Captures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2_64\\envs\\HIRA\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconsumers\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    577\u001b[0m     return [\n\u001b[0;32m    578\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_operation_by_name_unsafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mconsumer_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    580\u001b[0m     ]\n\u001b[0;32m    581\u001b[0m     \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2_64\\envs\\HIRA\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    577\u001b[0m     return [\n\u001b[0;32m    578\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_operation_by_name_unsafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mconsumer_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    580\u001b[0m     ]\n\u001b[0;32m    581\u001b[0m     \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2_64\\envs\\HIRA\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_get_operation_by_name_unsafe\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   3639\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3640\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3641\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nodes_by_name\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3643\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_get_operation_by_tf_operation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf_oper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'gradients_4/LSTM2_264/basic_lstm_cell/Add_44_grad/Sum'"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "### Global Parameters ###\n",
    "checkpoint = config.CHECKPOINT\n",
    "model_path = config.train_model_path\n",
    "model_name = config.train_model_name\n",
    "start_epoch = config.start_epoch\n",
    "\n",
    "word_count_threshold = config.WC_threshold\n",
    "\n",
    "### Train Parameters ###\n",
    "dim_wordvec = 300\n",
    "dim_hidden = 1000\n",
    "\n",
    "n_encode_lstm_step = 22 + 22\n",
    "n_decode_lstm_step = 22\n",
    "\n",
    "epochs = 500\n",
    "batch_size = 100\n",
    "learning_rate = 0.0001\n",
    "\n",
    "\n",
    "def pad_sequences(sequences, maxlen=None, dtype='int32', padding='pre', truncating='pre', value=0.):\n",
    "    if not hasattr(sequences, '__len__'):\n",
    "        raise ValueError('`sequences` must be iterable.')\n",
    "    lengths = []\n",
    "    for x in sequences:\n",
    "        if not hasattr(x, '__len__'):\n",
    "            raise ValueError('`sequences` must be a list of iterables. '\n",
    "                             'Found non-iterable: ' + str(x))\n",
    "        lengths.append(len(x))\n",
    "\n",
    "    num_samples = len(sequences)\n",
    "    if maxlen is None:\n",
    "        maxlen = np.max(lengths)\n",
    "\n",
    "    # take the sample shape from the first non empty sequence\n",
    "    # checking for consistency in the main loop below.\n",
    "    sample_shape = tuple()\n",
    "    for s in sequences:\n",
    "        if len(s) > 0:\n",
    "            sample_shape = np.asarray(s).shape[1:]\n",
    "            break\n",
    "\n",
    "    x = (np.ones((num_samples, maxlen) + sample_shape) * value).astype(dtype)\n",
    "    for idx, s in enumerate(sequences):\n",
    "        if not len(s):\n",
    "            continue  # empty list/array was found\n",
    "        if truncating == 'pre':\n",
    "            trunc = s[-maxlen:]\n",
    "        elif truncating == 'post':\n",
    "            trunc = s[:maxlen]\n",
    "        else:\n",
    "            raise ValueError('Truncating type \"%s\" not understood' % truncating)\n",
    "\n",
    "        # check `trunc` has expected shape\n",
    "        trunc = np.asarray(trunc, dtype=dtype)\n",
    "        if trunc.shape[1:] != sample_shape:\n",
    "            raise ValueError('Shape of sample %s of sequence at position %s is different from expected shape %s' %\n",
    "                             (trunc.shape[1:], idx, sample_shape))\n",
    "\n",
    "        if padding == 'post':\n",
    "            x[idx, :len(trunc)] = trunc\n",
    "        elif padding == 'pre':\n",
    "            x[idx, -len(trunc):] = trunc\n",
    "        else:\n",
    "            raise ValueError('Padding type \"%s\" not understood' % padding)\n",
    "    return x\n",
    "\n",
    "def train():\n",
    "    wordtoix, ixtoword, bias_init_vector = preProBuildWordVocab(word_count_threshold=word_count_threshold)\n",
    "    word_vector = KeyedVectors.load_word2vec_format('model/word_vector.bin', binary=True)\n",
    "    print(dim_wordvec,len(wordtoix), dim_hidden, batch_size,n_encode_lstm_step, n_decode_lstm_step,bias_init_vector,learning_rate)\n",
    "\n",
    "    model = Seq2Seq_chatbot(\n",
    "            dim_wordvec=dim_wordvec,\n",
    "            n_words=len(wordtoix),\n",
    "            dim_hidden=dim_hidden,\n",
    "            batch_size=batch_size,\n",
    "            n_encode_lstm_step=n_encode_lstm_step,\n",
    "            n_decode_lstm_step=n_decode_lstm_step,\n",
    "            bias_init_vector=bias_init_vector,\n",
    "            lr=learning_rate)\n",
    "\n",
    "    train_op, tf_loss, word_vectors, tf_caption, tf_caption_mask, inter_value = model.build_model()\n",
    "\n",
    "    saver = tf.train.Saver(max_to_keep=100)\n",
    "    #save_path = saver.save(sess, \"/model/model.ckpt\")\n",
    "\n",
    "    sess = tf.InteractiveSession()\n",
    "    \n",
    "#    if checkpoint:\n",
    "#        print(\"Use Model {}.\".format(model_name))\n",
    "#        saver.restore(sess, os.path.join(model_path, model_name))\n",
    "#        print(\"Model {} restored.\".format(model_name))\n",
    "#    else:\n",
    "    print(\"Restart training...\")\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    dr = Data_Reader()\n",
    "\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "        n_batch = dr.get_batch_num(batch_size)\n",
    "        for batch in range(n_batch):\n",
    "            start_time = time.time()\n",
    "\n",
    "            batch_X, batch_Y = dr.generate_training_batch(batch_size)\n",
    "\n",
    "            for i in range(len(batch_X)):\n",
    "                batch_X[i] = [word_vector[w] if w in word_vector else np.zeros(dim_wordvec) for w in batch_X[i]]\n",
    "                # batch_X[i].insert(0, np.random.normal(size=(dim_wordvec,))) # insert random normal at the first step\n",
    "                if len(batch_X[i]) > n_encode_lstm_step:\n",
    "                    batch_X[i] = batch_X[i][:n_encode_lstm_step]\n",
    "                else:\n",
    "                    for _ in range(len(batch_X[i]), n_encode_lstm_step):\n",
    "                        batch_X[i].append(np.zeros(dim_wordvec))\n",
    "\n",
    "            current_feats = np.array(batch_X)\n",
    "\n",
    "            current_captions = batch_Y\n",
    "            current_captions = map(lambda x: '<bos> ' + x, current_captions)\n",
    "            current_captions = map(lambda x: x.replace('.', ''), current_captions)\n",
    "            current_captions = map(lambda x: x.replace(',', ''), current_captions)\n",
    "            current_captions = map(lambda x: x.replace('\"', ''), current_captions)\n",
    "            current_captions = map(lambda x: x.replace('\\n', ''), current_captions)\n",
    "            current_captions = map(lambda x: x.replace('?', ''), current_captions)\n",
    "            current_captions = map(lambda x: x.replace('!', ''), current_captions)\n",
    "            current_captions = map(lambda x: x.replace('\\\\', ''), current_captions)\n",
    "            current_captions = list(map(lambda x: x.replace('/', ''), current_captions))\n",
    "            \n",
    "\n",
    "            for idx, each_cap in enumerate(current_captions):\n",
    "                word = each_cap.lower().split(' ')\n",
    "                if len(word) < n_decode_lstm_step:\n",
    "                    current_captions[idx] = current_captions[idx] + ' <eos>'\n",
    "                    #print(current_captions)\n",
    "                else:\n",
    "                    new_word = ''\n",
    "                    for i in range(n_decode_lstm_step-1):\n",
    "                        new_word = new_word + word[i] + ' '\n",
    "                    current_captions[idx] = new_word + '<eos>'\n",
    "                    #print(current_captions)\n",
    "\n",
    "            current_caption_ind = []\n",
    "            for cap in current_captions:\n",
    "                current_word_ind = []\n",
    "                for word in cap.lower().split(' '):\n",
    "                    if word in wordtoix:\n",
    "                        current_word_ind.append(wordtoix[word])\n",
    "                    else:\n",
    "                        current_word_ind.append(wordtoix['<unk>'])\n",
    "                current_caption_ind.append(current_word_ind)\n",
    "\n",
    "            current_caption_matrix = pad_sequences(current_caption_ind, padding='post', maxlen=n_decode_lstm_step)\n",
    "            current_caption_matrix = np.hstack([current_caption_matrix, np.zeros([len(current_caption_matrix), 1])]).astype(int)\n",
    "            current_caption_masks = np.zeros((current_caption_matrix.shape[0], current_caption_matrix.shape[1]))\n",
    "            nonzeros = np.array(list(map(lambda x: (x != 0).sum() + 1, current_caption_matrix)))\n",
    "            for ind, row in enumerate(current_caption_masks):\n",
    "                row[:nonzeros[ind]] = 1\n",
    "\n",
    "            if batch % 100 == 0:\n",
    "                _, loss_val = sess.run(\n",
    "                        [train_op, tf_loss],\n",
    "                        feed_dict={\n",
    "                            word_vectors: current_feats,\n",
    "                            tf_caption: current_caption_matrix,\n",
    "                            tf_caption_mask: current_caption_masks\n",
    "                        })\n",
    "                print(\"Epoch: {}, batch: {}, loss: {}, Elapsed time: {}\".format(epoch, batch, loss_val, time.time() - start_time))\n",
    "            else:\n",
    "                _ = sess.run(train_op,\n",
    "                             feed_dict={\n",
    "                                word_vectors: current_feats,\n",
    "                                tf_caption: current_caption_matrix,\n",
    "                                tf_caption_mask: current_caption_masks\n",
    "                            })\n",
    "\n",
    "\n",
    "        print(\"Epoch \", epoch, \" is done. Saving the model ...\")\n",
    "        saver.save(sess, os.path.join(model_path, 'model'), global_step=epoch)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HIRA_3",
   "language": "python",
   "name": "hira_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
